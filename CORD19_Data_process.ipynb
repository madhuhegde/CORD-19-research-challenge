{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-using some functions from https://www.kaggle.com/xhlulu/cord-19-eda-parse-json-and-generate-clean-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk import tokenize #import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_name(author):\n",
    "    middle_name = \" \".join(author['middle'])\n",
    "    \n",
    "    if author['middle']:\n",
    "        return \" \".join([author['first'], middle_name, author['last']])\n",
    "    else:\n",
    "        return \" \".join([author['first'], author['last']])\n",
    "\n",
    "\n",
    "def format_affiliation(affiliation):\n",
    "    text = []\n",
    "    location = affiliation.get('location')\n",
    "    if location:\n",
    "        text.extend(list(affiliation['location'].values()))\n",
    "    \n",
    "    institution = affiliation.get('institution')\n",
    "    if institution:\n",
    "        text = [institution] + text\n",
    "    return \", \".join(text)\n",
    "\n",
    "def format_authors(authors, with_affiliation=False):\n",
    "    name_ls = []\n",
    "    \n",
    "    for author in authors:\n",
    "        name = format_name(author)\n",
    "        if with_affiliation:\n",
    "            affiliation = format_affiliation(author['affiliation'])\n",
    "            if affiliation:\n",
    "                name_ls.append(f\"{name} ({affiliation})\")\n",
    "            else:\n",
    "                name_ls.append(name)\n",
    "        else:\n",
    "            name_ls.append(name)\n",
    "    \n",
    "    return \", \".join(name_ls)\n",
    "\n",
    "def format_body(body_text):\n",
    "    texts = [(di['section'], di['text']) for di in body_text]\n",
    "    texts_di = {di['section']: \"\" for di in body_text}\n",
    "    \n",
    "    for section, text in texts:\n",
    "        texts_di[section] += text\n",
    "\n",
    "    body = \"\"\n",
    "\n",
    "    for section, text in texts_di.items():\n",
    "        body += section\n",
    "        body += \"\\n\\n\"\n",
    "        body += text\n",
    "        body += \"\\n\\n\"\n",
    "    \n",
    "    return body\n",
    "\n",
    "def format_bib(bibs):\n",
    "    if type(bibs) == dict:\n",
    "        bibs = list(bibs.values())\n",
    "    bibs = deepcopy(bibs)\n",
    "    formatted = []\n",
    "    \n",
    "    for bib in bibs:\n",
    "        bib['authors'] = format_authors(\n",
    "            bib['authors'], \n",
    "            with_affiliation=False\n",
    "        )\n",
    "        formatted_ls = [str(bib[k]) for k in ['title', 'authors', 'venue', 'year']]\n",
    "        formatted.append(\", \".join(formatted_ls))\n",
    "\n",
    "    return \"; \".join(formatted)\n",
    "\n",
    "\n",
    "def format_body_text(body_text):\n",
    "    \n",
    "    body = \"\"\n",
    "\n",
    "    for di in body_text:\n",
    "        text = di['text']\n",
    "        body += text\n",
    "    return body\n",
    "    \n",
    "    \n",
    "def format_corpus_text(body_text, min_len=18, max_len=128):\n",
    "    junk_text = \"copyright\"\n",
    "    \n",
    "    def remove_braces_brackets(body_text):\n",
    "        body_text = re.sub(r'\\([0-9]+\\)', '', body_text)\n",
    "        body_text = re.sub(r'\\[[^)]*\\]', '', body_text)\n",
    "        return(body_text)\n",
    "        \n",
    "    body_text = remove_braces_brackets(body_text)\n",
    "    text_lines = []\n",
    "    token_lines = tokenize.sent_tokenize(body_text)\n",
    "    for line in token_lines:\n",
    "      \n",
    "        words = line.split()\n",
    "        if junk_text not in words:\n",
    "             max_word_len = len(max(words, key=len))\n",
    "             if (len(words) > min_len) and (len(words) < max_len) and max_word_len > 5:\n",
    "                 text_lines.append(line)\n",
    "    \n",
    "    return(text_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_filenames(folder):\n",
    "    filenames = os.listdir(folder)\n",
    "    print(\"Number of articles retrieved from the folder:\", len(filenames))\n",
    "    files = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        filename = folder + filename\n",
    "        file = json.load(open(filename, 'rb'))\n",
    "        files.append(file)\n",
    "    return(files)    \n",
    "\n",
    "folder = './input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/'\n",
    "all_files = find_filenames(folder)\n",
    "folder = biorxiv_dir = './input/CORD-19-research-challenge/comm_use_subset/comm_use_subset/'\n",
    "all_files.extend(find_filenames(folder))\n",
    "folder = biorxiv_dir = './input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/'\n",
    "all_files.extend(find_filenames(folder))\n",
    "folder = './input/CORD-19-research-challenge/custom_license/custom_license/'\n",
    "all_files.extend(find_filenames(folder))\n",
    "\n",
    "print(\"Total number of articles retrieved:\", len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles retrieved from the folder: 885\n",
      "Number of articles retrieved from the folder: 9118\n",
      "Number of articles retrieved from the folder: 2353\n",
      "Number of articles retrieved from the folder: 16959\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd5570669e643678ddaf9b73692367a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29315), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_files = []\n",
    "\n",
    "for file in tqdm(all_files):\n",
    "    temp = format_body_text(file['body_text'])\n",
    "    temp = temp.replace('\\n',' ')\n",
    "   \n",
    "    test = []\n",
    "    test.append(temp)\n",
    "    temp = test\n",
    "    features = [\n",
    "        file['metadata']['title'],\n",
    "        format_authors(file['metadata']['authors'], \n",
    "                       with_affiliation=True),\n",
    "        temp,\n",
    "    ]\n",
    "    \n",
    "    cleaned_files.append(features)\n",
    "    \n",
    "col_names = [\n",
    "    'title',\n",
    "    'authors',\n",
    "    'paragraphs']\n",
    "\n",
    "clean_df = pd.DataFrame(cleaned_files, columns=col_names)\n",
    "clean_df.head()\n",
    "\n",
    "# CSV file is used by DocRetriver() and DocReader()\n",
    "clean_df.to_csv('./input/covid_corpus.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dc2679919a4333966e9df92e15c922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29315), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The covid_corpus.txt is raw text file used for pre-training of BERT\n",
    "corpus_text = []\n",
    "\n",
    "for file in tqdm(all_files):\n",
    "    file_text = format_body_text(file['body_text'])\n",
    "    \n",
    "    file_lines = format_corpus_text(file_text)\n",
    "    if(len(file_lines)>5):\n",
    "        corpus_text.append(file_lines)\n",
    "\n",
    "with open('./input/covid_corpus.txt', 'w') as corp_file:\n",
    "    for lines in corpus_text:\n",
    "        for line in lines:\n",
    "                line = line.lower()\n",
    "                corp_file.write(\"%s\\n\" %line)\n",
    "        corp_file.write(\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
